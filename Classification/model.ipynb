{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "import graphviz\n",
    "from graphviz import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prep_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acquire import get_titanic_data\n",
    "from prep_titanic import prep_titanic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class  deck  embark_town  alone  \n",
       "0        S  Third  None  Southampton      0  \n",
       "1        C  First     C    Cherbourg      0  \n",
       "2        S  Third  None  Southampton      1  \n",
       "3        S  First     C  Southampton      0  \n",
       "4        S  Third  None  Southampton      1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = acquire.get_titanic_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>embarked_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class  embark_town  alone  embarked_encode  \n",
       "0        S  Third  Southampton      0                3  \n",
       "1        C  First    Cherbourg      0                0  \n",
       "2        S  Third  Southampton      1                3  \n",
       "3        S  First  Southampton      0                3  \n",
       "4        S  Third  Southampton      1                3  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = prep_titanic_data(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sex(df):\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(df.sex)\n",
    "    return df.assign(sex_encode = encoder.transform(df.sex))\n",
    "df = encode_sex(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>embarked_encode</th>\n",
       "      <th>sex_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class  embark_town  alone  embarked_encode  sex_encode  \n",
       "0        S  Third  Southampton      0                3           1  \n",
       "1        C  First    Cherbourg      0                0           0  \n",
       "2        S  Third  Southampton      1                3           0  \n",
       "3        S  First  Southampton      0                3           0  \n",
       "4        S  Third  Southampton      1                3           1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_age_na = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_id       0\n",
       "survived           0\n",
       "pclass             0\n",
       "sex                0\n",
       "age                0\n",
       "sibsp              0\n",
       "parch              0\n",
       "fare               0\n",
       "embarked           0\n",
       "class              0\n",
       "embark_town        0\n",
       "alone              0\n",
       "embarked_encode    0\n",
       "sex_encode         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drop_age_na.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>sex_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass   age  sibsp  parch  sex_encode\n",
       "60        3  22.0      0      0           1\n",
       "348       3   3.0      1      1           1\n",
       "606       3  30.0      0      0           1\n",
       "195       1  58.0      0      0           0\n",
       "56        2  21.0      0      0           0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_drop_age_na[['pclass', 'age', 'sibsp', 'parch', 'sex_encode']]\n",
    "y = df_drop_age_na[['survived']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(C=1, class_weight={1:2}, random_state = 123, solver='saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight={1: 2}, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=123, solver='saga',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.25329634  0.01860232 -0.04746574  0.4788608  -1.28895344]]\n",
      "Intercept: \n",
      " [0.77998646]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logit.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.76\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[221  72]\n",
      " [ 48 158]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred -</th>\n",
       "      <th>Pred +</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual -</th>\n",
       "      <td>221</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual +</th>\n",
       "      <td>48</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pred -  Pred +\n",
       "Actual -     221      72\n",
       "Actual +      48     158"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = pd.DataFrame(confusion_matrix(y_train, y_pred),\n",
    "             columns=['Pred -', 'Pred +'], index=['Actual -', 'Actual +'])\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.79       293\n",
      "           1       0.69      0.77      0.72       206\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       499\n",
      "   macro avg       0.75      0.76      0.76       499\n",
      "weighted avg       0.77      0.76      0.76       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sample that excludes the 177 passengers without an age:\n",
    "\n",
    "206 passengers actually survived. Of those that did actually survive, this model was able to predict 77% of them accurately based on the recall.\n",
    "\n",
    "230 passengers were predicted to have survived with this model.\n",
    "Out of those that were predicted to have survived, our precision for TP's, were 69%.\n",
    "This would mean that out of predicted positives, 31% were false positives.\n",
    "\n",
    "293 did not survive.  Of those that did not actually survive, this model was able to predict 75% of them accurately based on the recall.\n",
    "\n",
    "269 passengers were predicted to not have survived.\n",
    "Out of those that were predicted to have survived, our precision for TP's, was 82%.\n",
    "This would mean that out of predicted positives, 18% were false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df_drop_age_na[['pclass', 'age', 'parch', 'sex_encode']]\n",
    "y1 = df_drop_age_na[['survived']]\n",
    "\n",
    "def analyze_log_reg_model(X_df, y_df, solver_name):\n",
    "    print('Results using ' + str(solver_name) + ' as the solver.')\n",
    "    print('-----')\n",
    "    \n",
    "    X_df_train, X_df_test, y_df_train, y_df_test = train_test_split(X_df, y_df, test_size = .30, random_state = 123)\n",
    "    print(X_df_train.head())\n",
    "    \n",
    "    logit = LogisticRegression(C=1, class_weight={1:2}, random_state = 123, solver=solver_name)\n",
    "    logit.fit(X_df_train, y_df_train)\n",
    "    print('-----')\n",
    "    \n",
    "    print('Coefficient: \\n', logit.coef_)\n",
    "    print('Intercept: \\n', logit.intercept_)\n",
    "    print('-----')\n",
    "    \n",
    "    y_df_pred = logit.predict(X_df_train)\n",
    "    y_df_pred_proba = logit.predict_proba(X_df_train)\n",
    "    print('Accuracy of Logistic Regression classifier on training set: {:.5f}'\n",
    "     .format(logit.score(X_df_train, y_df_train)))\n",
    "    print('-----')\n",
    "    \n",
    "    print('The results of running the model on the test sample:')\n",
    "    \n",
    "    cm = pd.DataFrame(confusion_matrix(y_df_train, y_df_pred),\n",
    "             columns=['Pred -', 'Pred +'], index=['Actual -', 'Actual +'])\n",
    "    print(cm)\n",
    "    print('-----')\n",
    "    \n",
    "    print(classification_report(y_df_train, y_df_pred, digits=4))\n",
    "    print('-----')\n",
    "    \n",
    "    y_df_pred_test = logit.predict(X_df_test)\n",
    "    y_df_pred_proba_test = logit.predict_proba(X_df_test)\n",
    "    print('Accuracy of Logistic Regression classifier on test set: {:.5f}'\n",
    "     .format(logit.score(X_df_test, y_df_test)))\n",
    "    print('-----')\n",
    "    \n",
    "    print('-----')\n",
    "    print('For the sample that excludes the 177 passengers without an age:')\n",
    "\n",
    "\n",
    "#     print('{:.0f} passengers actually survived. Of those that did not actually survive, \\\n",
    "#     this model was able to predict {:.2f}% of them accurately based on the recall.'.format((cm.iloc[0][0]) + (cm.iloc[0][1])), #need equation for percentage)\n",
    "\n",
    "#     230 passengers were predicted to have survived with this model.\n",
    "#     Out of those that were predicted to have survived, our precision for TP's, was 69%.\n",
    "#     This would mean that out of predicted positives, 31% were false positives.\n",
    "\n",
    "#     293 did not survive.  Of those that did not actually survive, this model was able to predict 75% of them accurately based on the recall.\n",
    "\n",
    "#     269 passengers were predicted to not have survived.\n",
    "#     Out of those that were predicted to have survived, our precision for TP's, was 82%.\n",
    "#     This would mean that out of predicted positives, 18% were false negatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using saga as the solver.\n",
      "-----\n",
      "     pclass   age  parch  sex_encode\n",
      "60        3  22.0      0           1\n",
      "348       3   3.0      1           1\n",
      "606       3  30.0      0           1\n",
      "195       1  58.0      0           0\n",
      "56        2  21.0      0           0\n",
      "-----\n",
      "Coefficient: \n",
      " [[-0.26035825  0.01864     0.47079312 -1.29017474]]\n",
      "Intercept: \n",
      " [0.77681435]\n",
      "-----\n",
      "Accuracy of Logistic Regression classifier on training set: 0.75551\n",
      "-----\n",
      "The results of running the model on the test sample:\n",
      "          Pred -  Pred +\n",
      "Actual -     218      75\n",
      "Actual +      47     159\n",
      "-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8226    0.7440    0.7814       293\n",
      "           1     0.6795    0.7718    0.7227       206\n",
      "\n",
      "   micro avg     0.7555    0.7555    0.7555       499\n",
      "   macro avg     0.7511    0.7579    0.7520       499\n",
      "weighted avg     0.7635    0.7555    0.7572       499\n",
      "\n",
      "-----\n",
      "Accuracy of Logistic Regression classifier on test set: 0.66512\n",
      "-----\n",
      "-----\n",
      "For the sample that excludes the 177 passengers without an age:\n"
     ]
    }
   ],
   "source": [
    "analyze_log_reg_model(X1, y1, 'saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using liblinear as the solver.\n",
      "-----\n",
      "     pclass   age  parch  sex_encode\n",
      "60        3  22.0      0           1\n",
      "348       3   3.0      1           1\n",
      "606       3  30.0      0           1\n",
      "195       1  58.0      0           0\n",
      "56        2  21.0      0           0\n",
      "-----\n",
      "Coefficient: \n",
      " [[-0.92706373 -0.01779685  0.09747168 -2.29284896]]\n",
      "Intercept: \n",
      " [4.20419336]\n",
      "-----\n",
      "Accuracy of Logistic Regression classifier on training set: 0.78958\n",
      "-----\n",
      "The results of running the model on the test sample:\n",
      "          Pred -  Pred +\n",
      "Actual -     219      74\n",
      "Actual +      31     175\n",
      "-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8760    0.7474    0.8066       293\n",
      "           1     0.7028    0.8495    0.7692       206\n",
      "\n",
      "   micro avg     0.7896    0.7896    0.7896       499\n",
      "   macro avg     0.7894    0.7985    0.7879       499\n",
      "weighted avg     0.8045    0.7896    0.7912       499\n",
      "\n",
      "-----\n",
      "Accuracy of Logistic Regression classifier on test set: 0.75814\n",
      "-----\n",
      "-----\n",
      "For the sample that excludes the 177 passengers without an age:\n"
     ]
    }
   ],
   "source": [
    "analyze_log_reg_model(X1, y1, 'liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df_drop_age_na[['pclass', 'age', 'parch', 'sex_encode', 'sibsp']]\n",
    "y2 = df_drop_age_na[['survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using saga as the solver.\n",
      "-----\n",
      "     pclass   age  parch  sex_encode  sibsp\n",
      "60        3  22.0      0           1      0\n",
      "348       3   3.0      1           1      1\n",
      "606       3  30.0      0           1      0\n",
      "195       1  58.0      0           0      0\n",
      "56        2  21.0      0           0      0\n",
      "-----\n",
      "Coefficient: \n",
      " [[-0.25329634  0.01860232  0.4788608  -1.28895344 -0.04746574]]\n",
      "Intercept: \n",
      " [0.77998646]\n",
      "-----\n",
      "Accuracy of Logistic Regression classifier on training set: 0.75952\n",
      "-----\n",
      "The results of running the model on the test sample:\n",
      "          Pred -  Pred +\n",
      "Actual -     221      72\n",
      "Actual +      48     158\n",
      "-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8216    0.7543    0.7865       293\n",
      "           1     0.6870    0.7670    0.7248       206\n",
      "\n",
      "   micro avg     0.7595    0.7595    0.7595       499\n",
      "   macro avg     0.7543    0.7606    0.7556       499\n",
      "weighted avg     0.7660    0.7595    0.7610       499\n",
      "\n",
      "-----\n",
      "Accuracy of Logistic Regression classifier on test set: 0.66512\n",
      "-----\n",
      "-----\n",
      "For the sample that excludes the 177 passengers without an age:\n"
     ]
    }
   ],
   "source": [
    "analyze_log_reg_model(X2, y2, 'saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using liblinear as the solver.\n",
      "-----\n",
      "     pclass   age  parch  sex_encode  sibsp\n",
      "60        3  22.0      0           1      0\n",
      "348       3   3.0      1           1      1\n",
      "606       3  30.0      0           1      0\n",
      "195       1  58.0      0           0      0\n",
      "56        2  21.0      0           0      0\n",
      "-----\n",
      "Coefficient: \n",
      " [[-0.93271629 -0.02030594  0.18904603 -2.29565391 -0.26499086]]\n",
      "Intercept: \n",
      " [4.3924343]\n",
      "-----\n",
      "Accuracy of Logistic Regression classifier on training set: 0.77956\n",
      "-----\n",
      "The results of running the model on the test sample:\n",
      "          Pred -  Pred +\n",
      "Actual -     222      71\n",
      "Actual +      39     167\n",
      "-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8506    0.7577    0.8014       293\n",
      "           1     0.7017    0.8107    0.7523       206\n",
      "\n",
      "   micro avg     0.7796    0.7796    0.7796       499\n",
      "   macro avg     0.7761    0.7842    0.7768       499\n",
      "weighted avg     0.7891    0.7796    0.7811       499\n",
      "\n",
      "-----\n",
      "Accuracy of Logistic Regression classifier on test set: 0.75814\n",
      "-----\n",
      "-----\n",
      "For the sample that excludes the 177 passengers without an age:\n"
     ]
    }
   ],
   "source": [
    "analyze_log_reg_model(X2, y2, 'liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pclass   age  parch  sex_encode\n",
      "60        3  22.0      0           1\n",
      "348       3   3.0      1           1\n",
      "606       3  30.0      0           1\n",
      "195       1  58.0      0           0\n",
      "56        2  21.0      0           0\n"
     ]
    }
   ],
   "source": [
    "X1_df_train, X1_df_test, y1_df_train, y1_df_test = train_test_split(X1, y1, test_size = .30, random_state = 123)\n",
    "print(X1_df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight={1: 2}, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=123, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_fit = LogisticRegression(C=1, class_weight={1:2}, random_state = 123, solver='liblinear')\n",
    "logit_fit.fit(X1_df_train, y1_df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acquire import get_iris_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_iris import prep_iris_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measurement_id</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "      <th>species_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   measurement_id  sepal_length  sepal_width  petal_length  petal_width  \\\n",
       "0               1           5.1          3.5           1.4          0.2   \n",
       "1               2           4.9          3.0           1.4          0.2   \n",
       "2               3           4.7          3.2           1.3          0.2   \n",
       "3               4           4.6          3.1           1.5          0.2   \n",
       "4               5           5.0          3.6           1.4          0.2   \n",
       "\n",
       "  species  species_enc  \n",
       "0  setosa            0  \n",
       "1  setosa            0  \n",
       "2  setosa            0  \n",
       "3  setosa            0  \n",
       "4  setosa            0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = prep_iris_data(get_iris_data())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "measurement_id    0\n",
       "sepal_length      0\n",
       "sepal_width       0\n",
       "petal_length      0\n",
       "petal_width       0\n",
       "species           0\n",
       "species_enc       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "114           5.8          2.8           5.1          2.4\n",
       "136           6.3          3.4           5.6          2.4\n",
       "53            5.5          2.3           4.0          1.3\n",
       "19            5.1          3.8           1.5          0.3\n",
       "38            4.4          3.0           1.3          0.2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3 = df.drop(['measurement_id', 'species', 'species_enc'], axis=1)\n",
    "y3 = df[['species']]\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size = .30, random_state=123)\n",
    "X3_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X3_train, y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['virginica', 'virginica', 'versicolor', 'setosa', 'setosa'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3_pred = clf.predict(X3_train)\n",
    "y3_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ]])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3_pred_proba = clf.predict_proba(X3_train)\n",
    "y3_pred_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.98095\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.5f}'.format(clf.score(X3_train, y3_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        species\n",
       "114   virginica\n",
       "136   virginica\n",
       "53   versicolor\n",
       "19       setosa\n",
       "38       setosa"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "versicolor    40\n",
       "virginica     33\n",
       "setosa        32\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3_train['species'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred Setosa</th>\n",
       "      <th>Pred Versicolor</th>\n",
       "      <th>Predicted Virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Setosa</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Versicolor</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Virginica</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Pred Setosa  Pred Versicolor  Predicted Virginica\n",
       "Actual Setosa               32                0                    0\n",
       "Actual Versicolor            0               40                    0\n",
       "Actual Virginica             0                2                   31"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = pd.DataFrame(confusion_matrix(y3_train, y3_pred),\n",
    "             columns=['Pred Setosa', 'Pred Versicolor', 'Predicted Virginica'], index=['Actual Setosa', 'Actual Versicolor', 'Actual Virginica'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        32\n",
      "  versicolor       0.95      1.00      0.98        40\n",
      "   virginica       1.00      0.94      0.97        33\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       105\n",
      "   macro avg       0.98      0.98      0.98       105\n",
      "weighted avg       0.98      0.98      0.98       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y3_train, y3_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on test set: 0.93\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'.format(clf.score(X3_test, y3_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iris_decision_tree2.pdf'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(iris.data, iris.target)\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None)\n",
    "graph = graphviz.Source(dot_data)\n",
    "\n",
    "graph.render('iris_decision_tree2', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4 = df.drop(['measurement_id', 'species', 'species_enc'], axis=1)\n",
    "y4 = df[['species']]\n",
    "\n",
    "def analyze_decision_tree(X_df, y_df, string_criterion, max_depth_input):\n",
    "    features = list(X_df)\n",
    "    \n",
    "    print('Results using ' + str(string_criterion) + ' as the measure of impurity and ' + str(max_depth_input) + ' as the depth.')\n",
    "    print('The features being used: ' + str(features))\n",
    "    print('-----')\n",
    "    X_df_train, X_df_test, y_df_train, y_df_test = train_test_split(X_df, y_df, test_size = .30, random_state=123)\n",
    "    X_df_train.head()\n",
    "\n",
    "    clf = DecisionTreeClassifier(criterion=string_criterion, max_depth=max_depth_input, random_state=123)\n",
    "\n",
    "    clf.fit(X_df_train, y_df_train)\n",
    "\n",
    "    y_df_pred = clf.predict(X_df_train)\n",
    "    print('Head of predicted on X_train:')\n",
    "    print(y_df_pred[0:5])\n",
    "    print('-----')\n",
    "\n",
    "    y_df_pred_proba = clf.predict_proba(X_df_train)\n",
    "    print('Head of probabilities on X_train:')\n",
    "    print(y_df_pred_proba[0:5])\n",
    "    print('-----')\n",
    "\n",
    "    print('Accuracy of Decision Tree classifier on training set: {:.8f}'.format(clf.score(X_df_train, y_df_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using entropy as the measure of impurity and 3 as the depth.\n",
      "The features being used: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "['virginica' 'virginica' 'versicolor' 'setosa' 'setosa']\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0.    0.    1.   ]\n",
      " [0.    0.    1.   ]\n",
      " [0.    0.975 0.025]\n",
      " [1.    0.    0.   ]\n",
      " [1.    0.    0.   ]]\n",
      "-----\n",
      "Accuracy of Decision Tree classifier on training set: 0.98095238\n"
     ]
    }
   ],
   "source": [
    "analyze_decision_tree(X4, y4, 'entropy', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using gini as the measure of impurity and 3 as the depth.\n",
      "The features being used: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "['virginica' 'virginica' 'versicolor' 'setosa' 'setosa']\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0.    0.    1.   ]\n",
      " [0.    0.    1.   ]\n",
      " [0.    0.975 0.025]\n",
      " [1.    0.    0.   ]\n",
      " [1.    0.    0.   ]]\n",
      "-----\n",
      "Accuracy of Decision Tree classifier on training set: 0.98095238\n"
     ]
    }
   ],
   "source": [
    "analyze_decision_tree(X4, y4, 'gini', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using gini as the measure of impurity and 4 as the depth.\n",
      "The features being used: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "['virginica' 'virginica' 'versicolor' 'setosa' 'setosa']\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "-----\n",
      "Accuracy of Decision Tree classifier on training set: 0.99047619\n"
     ]
    }
   ],
   "source": [
    "analyze_decision_tree(X4, y4, 'gini', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using entropy as the measure of impurity and 4 as the depth.\n",
      "The features being used: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "['virginica' 'virginica' 'versicolor' 'setosa' 'setosa']\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "-----\n",
      "Accuracy of Decision Tree classifier on training set: 0.99047619\n"
     ]
    }
   ],
   "source": [
    "analyze_decision_tree(X4, y4, 'entropy', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using entropy as the measure of impurity and 2 as the depth.\n",
      "The features being used: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "['virginica' 'virginica' 'versicolor' 'setosa' 'setosa']\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0.         0.03225806 0.96774194]\n",
      " [0.         0.03225806 0.96774194]\n",
      " [0.         0.92857143 0.07142857]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]]\n",
      "-----\n",
      "Accuracy of Decision Tree classifier on training set: 0.96190476\n"
     ]
    }
   ],
   "source": [
    "analyze_decision_tree(X4, y4, 'entropy', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using gini as the measure of impurity and 2 as the depth.\n",
      "The features being used: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "['virginica' 'virginica' 'versicolor' 'setosa' 'setosa']\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0.         0.03225806 0.96774194]\n",
      " [0.         0.03225806 0.96774194]\n",
      " [0.         0.92857143 0.07142857]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]]\n",
      "-----\n",
      "Accuracy of Decision Tree classifier on training set: 0.96190476\n"
     ]
    }
   ],
   "source": [
    "analyze_decision_tree(X4, y4, 'gini', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using entropy as the measure of impurity and 3 as the depth.\n",
      "The features being used: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "['virginica' 'virginica' 'versicolor' 'setosa' 'setosa']\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0.    0.    1.   ]\n",
      " [0.    0.    1.   ]\n",
      " [0.    0.975 0.025]\n",
      " [1.    0.    0.   ]\n",
      " [1.    0.    0.   ]]\n",
      "-----\n",
      "Accuracy of Decision Tree classifier on training set: 0.98095238\n"
     ]
    }
   ],
   "source": [
    "analyze_decision_tree(X4, y4, 'entropy', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using gini as the measure of impurity and 6 as the depth.\n",
      "The features being used: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "['virginica' 'virginica' 'versicolor' 'setosa' 'setosa']\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "-----\n",
      "Accuracy of Decision Tree classifier on training set: 1.00000000\n"
     ]
    }
   ],
   "source": [
    "analyze_decision_tree(X4, y4, 'gini', 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using entropy as the measure of impurity and 6 as the depth.\n",
      "The features being used: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "['virginica' 'virginica' 'versicolor' 'setosa' 'setosa']\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "-----\n",
      "Accuracy of Decision Tree classifier on training set: 1.00000000\n"
     ]
    }
   ],
   "source": [
    "analyze_decision_tree(X4, y4, 'entropy', 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=123,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X4_df_train, X4_df_test, y4_df_train, y4_df_test = train_test_split(X4, y4, test_size = .30, random_state=123)\n",
    "X4_df_train.head()\n",
    "\n",
    "tree_fit = DecisionTreeClassifier(criterion='entropy', max_depth=6, random_state=123)\n",
    "\n",
    "tree_fit.fit(X4_df_train, y4_df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5 = df_drop_age_na[['pclass', 'age', 'parch', 'sex_encode']]\n",
    "y5 = df_drop_age_na[['survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using entropy as the measure of impurity and 5 as the depth.\n",
      "The features being used: ['pclass', 'age', 'parch', 'sex_encode']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "[0 0 0 1 1]\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0.9        0.1       ]\n",
      " [0.61111111 0.38888889]\n",
      " [0.9        0.1       ]\n",
      " [0.03030303 0.96969697]\n",
      " [0.         1.        ]]\n",
      "-----\n",
      "Accuracy of Decision Tree classifier on training set: 0.83567134\n"
     ]
    }
   ],
   "source": [
    "analyze_decision_tree(X5, y5, 'entropy', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using gini as the measure of impurity and 5 as the depth.\n",
      "The features being used: ['pclass', 'age', 'parch', 'sex_encode']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "[0 0 0 1 1]\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0.9        0.1       ]\n",
      " [0.61111111 0.38888889]\n",
      " [0.9        0.1       ]\n",
      " [0.         1.        ]\n",
      " [0.13333333 0.86666667]]\n",
      "-----\n",
      "Accuracy of Decision Tree classifier on training set: 0.84168337\n"
     ]
    }
   ],
   "source": [
    "analyze_decision_tree(X5, y5, 'gini', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "X6 = df_drop_age_na[['pclass', 'age', 'parch', 'sex_encode', 'sibsp']]\n",
    "y6 = df_drop_age_na[['survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using gini as the measure of impurity and 5 as the depth.\n",
      "The features being used: ['pclass', 'age', 'parch', 'sex_encode', 'sibsp']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "[0 1 0 1 1]\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0.9        0.1       ]\n",
      " [0.         1.        ]\n",
      " [0.9        0.1       ]\n",
      " [0.         1.        ]\n",
      " [0.13333333 0.86666667]]\n",
      "-----\n",
      "Accuracy of Decision Tree classifier on training set: 0.86372745\n"
     ]
    }
   ],
   "source": [
    "analyze_decision_tree(X6, y6, 'gini', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using entropy as the measure of impurity and 5 as the depth.\n",
      "The features being used: ['pclass', 'age', 'parch', 'sex_encode', 'sibsp']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "[0 1 0 1 1]\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0.88541667 0.11458333]\n",
      " [0.         1.        ]\n",
      " [0.88541667 0.11458333]\n",
      " [0.03030303 0.96969697]\n",
      " [0.         1.        ]]\n",
      "-----\n",
      "Accuracy of Decision Tree classifier on training set: 0.85971944\n"
     ]
    }
   ],
   "source": [
    "analyze_decision_tree(X6, y6, 'entropy', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classification_model(X_df, y_df, string_criterion, max_depth_input):   \n",
    "    \n",
    "    print('Results using ' + str(string_criterion) + ' as the measure of impurity and ' + str(max_depth_input) + ' as the depth.')\n",
    "    print('-----')\n",
    "    X_df_train, X_df_test, y_df_train, y_df_test = train_test_split(X_df, y_df, test_size = .30, random_state=123)\n",
    "    X_df_train.head()\n",
    "\n",
    "    clf = DecisionTreeClassifier(criterion=string_criterion, max_depth=max_depth_input, random_state=123)\n",
    "\n",
    "    clf.fit(X_df_train, y_df_train)\n",
    "\n",
    "    y_df_pred = clf.predict(X_df_train)\n",
    "    print('Head of predicted on X_train:')\n",
    "    print(y_df_pred[0:5])\n",
    "    print('-----')\n",
    "\n",
    "    y_df_pred_proba = clf.predict_proba(X_df_train)\n",
    "    print('Head of probabilities on X_train:')\n",
    "    print(y_df_pred_proba[0:5])\n",
    "    print('-----')\n",
    "\n",
    "    print('Accuracy of Decision Tree classifier on training set: {:.8f}'.format(clf.score(X_df_train, y_df_train)))\n",
    "    print('-----')\n",
    "    \n",
    "    \n",
    "    print('The results of running the model on the test sample:')\n",
    "    \n",
    "    cm = pd.DataFrame(confusion_matrix(y_df_train, y_df_pred),\n",
    "             columns=['Pred -', 'Pred +'], index=['Actual -', 'Actual +'])\n",
    "    print(cm)\n",
    "    print('-----')\n",
    "    \n",
    "    print(classification_report(y_df_train, y_df_pred, digits=4))\n",
    "    print('-----')\n",
    "    \n",
    "    y_df_pred_test = clf.predict(X_df_test)\n",
    "    y_df_pred_proba_test = clf.predict_proba(X_df_test)\n",
    "    print('Accuracy of Logistic Regression classifier on test set: {:.6f}'\n",
    "     .format(clf.score(X_df_test, y_df_test)))\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using gini as the measure of impurity and 5 as the depth.\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "[0 0 0 1 1]\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0.9        0.1       ]\n",
      " [0.61111111 0.38888889]\n",
      " [0.9        0.1       ]\n",
      " [0.         1.        ]\n",
      " [0.13333333 0.86666667]]\n",
      "-----\n",
      "Accuracy of Decision Tree classifier on training set: 0.84168337\n",
      "-----\n",
      "The results of running the model on the test sample:\n",
      "          Pred -  Pred +\n",
      "Actual -     258      35\n",
      "Actual +      44     162\n",
      "-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8543    0.8805    0.8672       293\n",
      "           1     0.8223    0.7864    0.8040       206\n",
      "\n",
      "   micro avg     0.8417    0.8417    0.8417       499\n",
      "   macro avg     0.8383    0.8335    0.8356       499\n",
      "weighted avg     0.8411    0.8417    0.8411       499\n",
      "\n",
      "-----\n",
      "Accuracy of Logistic Regression classifier on test set: 0.800000\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "test_classification_model(X5, y5, 'gini', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using gini as the measure of impurity and 6 as the depth.\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "[0 1 0 1 1]\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0.87857143 0.12142857]\n",
      " [0.         1.        ]\n",
      " [0.87857143 0.12142857]\n",
      " [0.         1.        ]\n",
      " [0.09090909 0.90909091]]\n",
      "-----\n",
      "Accuracy of Decision Tree classifier on training set: 0.86973948\n",
      "-----\n",
      "The results of running the model on the test sample:\n",
      "          Pred -  Pred +\n",
      "Actual -     275      18\n",
      "Actual +      47     159\n",
      "-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8540    0.9386    0.8943       293\n",
      "           1     0.8983    0.7718    0.8303       206\n",
      "\n",
      "   micro avg     0.8697    0.8697    0.8697       499\n",
      "   macro avg     0.8762    0.8552    0.8623       499\n",
      "weighted avg     0.8723    0.8697    0.8679       499\n",
      "\n",
      "-----\n",
      "Accuracy of Logistic Regression classifier on test set: 0.827907\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "test_classification_model(X6, y6, 'gini', 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_knn_iris(X_df, y_df, n_neighbor, weight):\n",
    "    features = list(X_df)\n",
    "    \n",
    "    print('Results using ' + str(weight) + ' as the measure of impurity and ' + str(n_neighbor) + ' as the number of neighbors.')\n",
    "    print('The features being used: ' + str(features))\n",
    "    print('-----')\n",
    "    X_df_train, X_df_test, y_df_train, y_df_test = train_test_split(X_df, y_df, test_size = .30, random_state=123)\n",
    "    X_df_train.head()\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbor, weights=weight)\n",
    "\n",
    "    knn.fit(X_df_train, y_df_train)\n",
    "\n",
    "    y_df_pred = knn.predict(X_df_train)\n",
    "    print('Head of predicted on X_train:')\n",
    "    print(y_df_pred[0:5])\n",
    "    print('-----')\n",
    "\n",
    "    y_df_pred_proba = knn.predict_proba(X_df_train)\n",
    "    print('Head of probabilities on X_train:')\n",
    "    print(y_df_pred_proba[0:5])\n",
    "    print('-----')\n",
    "\n",
    "    print('Accuracy of KNN classifier on training set: {:.8f}'.format(knn.score(X_df_train, y_df_train)))\n",
    "    print('-----')\n",
    "    \n",
    "    cm = pd.DataFrame(confusion_matrix(y_df_train, y_df_pred),\n",
    "             columns=['Pred Setosa', 'Pred Versicolor', 'Predicted Virginica'], index=['Actual Setosa', 'Actual Versicolor', 'Actual Virginica'])\n",
    "    \n",
    "    print(cm)\n",
    "    print('-----')\n",
    "    \n",
    "    print(classification_report(y_df_train, y_df_pred, digits=4))\n",
    "    print('-----')\n",
    "    \n",
    "    y_df_pred_test = knn.predict(X_df_test)\n",
    "    y_df_pred_proba_test = knn.predict_proba(X_df_test)\n",
    "    print('Accuracy of KNN classifier on train set: {:.6f}'\n",
    "     .format(knn.score(X_df_train, y_df_train)))\n",
    "    print('-----')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measurement_id</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "      <th>species_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   measurement_id  sepal_length  sepal_width  petal_length  petal_width  \\\n",
       "0               1           5.1          3.5           1.4          0.2   \n",
       "1               2           4.9          3.0           1.4          0.2   \n",
       "2               3           4.7          3.2           1.3          0.2   \n",
       "3               4           4.6          3.1           1.5          0.2   \n",
       "4               5           5.0          3.6           1.4          0.2   \n",
       "\n",
       "  species  species_enc  \n",
       "0  setosa            0  \n",
       "1  setosa            0  \n",
       "2  setosa            0  \n",
       "3  setosa            0  \n",
       "4  setosa            0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_iris_KNN_1 = df.drop(['measurement_id', 'species', 'species_enc'], axis=1)\n",
    "y_iris_KNN_1 = df[['species']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using uniform as the measure of impurity and 5 as the number of neighbors.\n",
      "The features being used: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "['virginica' 'virginica' 'versicolor' 'setosa' 'setosa']\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "-----\n",
      "Accuracy of KNN classifier on training set: 0.98095238\n",
      "-----\n",
      "                   Pred Setosa  Pred Versicolor  Predicted Virginica\n",
      "Actual Setosa               32                0                    0\n",
      "Actual Versicolor            0               39                    1\n",
      "Actual Virginica             0                1                   32\n",
      "-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa     1.0000    1.0000    1.0000        32\n",
      "  versicolor     0.9750    0.9750    0.9750        40\n",
      "   virginica     0.9697    0.9697    0.9697        33\n",
      "\n",
      "   micro avg     0.9810    0.9810    0.9810       105\n",
      "   macro avg     0.9816    0.9816    0.9816       105\n",
      "weighted avg     0.9810    0.9810    0.9810       105\n",
      "\n",
      "-----\n",
      "Accuracy of KNN classifier on train set: 0.980952\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "analyze_knn_iris(X_iris_KNN_1, y_iris_KNN_1, 5, 'uniform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "The accuracy for the model was 0.980952.  \n",
    "Precision for Versicolor indicates that of the 40 times this model predicted Versicolor, it was correct on 39 instances, 97.5%.\n",
    "Precision for Virginica indicates that of the 33 times this model predicted Versicolor, it was correct on 32 instances, 96.97%.\n",
    "Recall for Versicolor indicates that out of the actual Versicolor (40) the model predicted 39 correctly, 97.5%\n",
    "Recall for Virginica indicates that out of the actual Virginica (33) the model predicted 32 correctly, 96.97%\n",
    "F1-score is the average of the precision and recall for each actual value.\n",
    "Support indicates that there are a total of 32 Setosa, 40 Versicolor, and Virginica actuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using distance as the measure of impurity and 5 as the number of neighbors.\n",
      "The features being used: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "['virginica' 'virginica' 'versicolor' 'setosa' 'setosa']\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "-----\n",
      "Accuracy of KNN classifier on training set: 1.00000000\n",
      "-----\n",
      "                   Pred Setosa  Pred Versicolor  Predicted Virginica\n",
      "Actual Setosa               32                0                    0\n",
      "Actual Versicolor            0               40                    0\n",
      "Actual Virginica             0                0                   33\n",
      "-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa     1.0000    1.0000    1.0000        32\n",
      "  versicolor     1.0000    1.0000    1.0000        40\n",
      "   virginica     1.0000    1.0000    1.0000        33\n",
      "\n",
      "   micro avg     1.0000    1.0000    1.0000       105\n",
      "   macro avg     1.0000    1.0000    1.0000       105\n",
      "weighted avg     1.0000    1.0000    1.0000       105\n",
      "\n",
      "-----\n",
      "Accuracy of KNN classifier on train set: 1.000000\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "analyze_knn_iris(X_iris_KNN_1, y_iris_KNN_1, 5, 'distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using uniform as the measure of impurity and 10 as the number of neighbors.\n",
      "The features being used: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "['virginica' 'virginica' 'versicolor' 'setosa' 'setosa']\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0.  0.1 0.9]\n",
      " [0.  0.  1. ]\n",
      " [0.  1.  0. ]\n",
      " [1.  0.  0. ]\n",
      " [1.  0.  0. ]]\n",
      "-----\n",
      "Accuracy of KNN classifier on training set: 0.97142857\n",
      "-----\n",
      "                   Pred Setosa  Pred Versicolor  Predicted Virginica\n",
      "Actual Setosa               32                0                    0\n",
      "Actual Versicolor            0               39                    1\n",
      "Actual Virginica             0                2                   31\n",
      "-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa     1.0000    1.0000    1.0000        32\n",
      "  versicolor     0.9512    0.9750    0.9630        40\n",
      "   virginica     0.9688    0.9394    0.9538        33\n",
      "\n",
      "   micro avg     0.9714    0.9714    0.9714       105\n",
      "   macro avg     0.9733    0.9715    0.9723       105\n",
      "weighted avg     0.9716    0.9714    0.9714       105\n",
      "\n",
      "-----\n",
      "Accuracy of KNN classifier on train set: 0.971429\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "analyze_knn_iris(X_iris_KNN_1, y_iris_KNN_1, 10, 'uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using uniform as the measure of impurity and 20 as the number of neighbors.\n",
      "The features being used: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "['virginica' 'virginica' 'versicolor' 'setosa' 'setosa']\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0.   0.15 0.85]\n",
      " [0.   0.05 0.95]\n",
      " [0.   0.95 0.05]\n",
      " [1.   0.   0.  ]\n",
      " [1.   0.   0.  ]]\n",
      "-----\n",
      "Accuracy of KNN classifier on training set: 0.96190476\n",
      "-----\n",
      "                   Pred Setosa  Pred Versicolor  Predicted Virginica\n",
      "Actual Setosa               32                0                    0\n",
      "Actual Versicolor            0               39                    1\n",
      "Actual Virginica             0                3                   30\n",
      "-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa     1.0000    1.0000    1.0000        32\n",
      "  versicolor     0.9286    0.9750    0.9512        40\n",
      "   virginica     0.9677    0.9091    0.9375        33\n",
      "\n",
      "   micro avg     0.9619    0.9619    0.9619       105\n",
      "   macro avg     0.9654    0.9614    0.9629       105\n",
      "weighted avg     0.9627    0.9619    0.9618       105\n",
      "\n",
      "-----\n",
      "Accuracy of KNN classifier on train set: 0.961905\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "analyze_knn_iris(X_iris_KNN_1, y_iris_KNN_1, 20, 'uniform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best KNN model out of the 4 above was the model using 'Distance' as weights and setting K=5.  As K was increased, the model seemed to prone to being overfit and less acurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_iris_KNN_train, X_iris_KNN_test, y_iris_KNN_train, y_iris_KNN_test = train_test_split(X_iris_KNN_1, y_iris_KNN_1, test_size = .30, random_state=123)\n",
    "X_iris_KNN_train.head()\n",
    "\n",
    "knn_fit = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "\n",
    "knn_fit.fit(X_iris_KNN_train, y_iris_KNN_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_knn_binomial(X_df, y_df, n_neighbor, weight):\n",
    "    features = list(X_df)\n",
    "    \n",
    "    print('Results using ' + str(weight) + ' as the measure of impurity and ' + str(n_neighbor) + ' as the number of neighbors.')\n",
    "    print('The features being used: ' + str(features))\n",
    "    print('-----')\n",
    "    X_df_train, X_df_test, y_df_train, y_df_test = train_test_split(X_df, y_df, test_size = .30, random_state=123)\n",
    "    X_df_train.head()\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbor, weights=weight)\n",
    "\n",
    "    knn.fit(X_df_train, y_df_train)\n",
    "\n",
    "    y_df_pred = knn.predict(X_df_train)\n",
    "    print('Head of predicted on X_train:')\n",
    "    print(y_df_pred[0:5])\n",
    "    print('-----')\n",
    "\n",
    "    y_df_pred_proba = knn.predict_proba(X_df_train)\n",
    "    print('Head of probabilities on X_train:')\n",
    "    print(y_df_pred_proba[0:5])\n",
    "    print('-----')\n",
    "\n",
    "    print('Accuracy of KNN classifier on training set: {:.8f}'.format(knn.score(X_df_train, y_df_train)))\n",
    "    print('-----')\n",
    "    \n",
    "    cm = pd.DataFrame(confusion_matrix(y_df_train, y_df_pred),\n",
    "             columns=['Pred -', 'Pred +'], index=['Actual -', 'Actual +'])\n",
    "    \n",
    "    print(cm)\n",
    "    print('-----')\n",
    "    \n",
    "    print(classification_report(y_df_train, y_df_pred, digits=4))\n",
    "    print('-----')\n",
    "    \n",
    "    y_df_pred_test = knn.predict(X_df_test)\n",
    "    y_df_pred_proba_test = knn.predict_proba(X_df_test)\n",
    "    print('Accuracy of KNN classifier on train set: {:.6f}'\n",
    "     .format(knn.score(X_df_train, y_df_train)))\n",
    "    print('-----')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_titanic_KNN_1 = df_drop_age_na[['pclass', 'age', 'sibsp', 'parch', 'sex_encode']]\n",
    "y_titanic_KNN_1 = df_drop_age_na[['survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using uniform as the measure of impurity and 5 as the number of neighbors.\n",
      "The features being used: ['pclass', 'age', 'sibsp', 'parch', 'sex_encode']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "[0 1 0 1 1]\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[1.  0. ]\n",
      " [0.2 0.8]\n",
      " [1.  0. ]\n",
      " [0.2 0.8]\n",
      " [0.4 0.6]]\n",
      "-----\n",
      "Accuracy of KNN classifier on training set: 0.84368737\n",
      "-----\n",
      "          Pred -  Pred +\n",
      "Actual -     267      26\n",
      "Actual +      52     154\n",
      "-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8370    0.9113    0.8725       293\n",
      "           1     0.8556    0.7476    0.7979       206\n",
      "\n",
      "   micro avg     0.8437    0.8437    0.8437       499\n",
      "   macro avg     0.8463    0.8294    0.8352       499\n",
      "weighted avg     0.8447    0.8437    0.8417       499\n",
      "\n",
      "-----\n",
      "Accuracy of KNN classifier on train set: 0.843687\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "analyze_knn_binomial(X_titanic_KNN_1, y_titanic_KNN_1, 5, 'uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using distance as the measure of impurity and 5 as the number of neighbors.\n",
      "The features being used: ['pclass', 'age', 'sibsp', 'parch', 'sex_encode']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "[0 1 0 1 1]\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "-----\n",
      "Accuracy of KNN classifier on training set: 0.94589178\n",
      "-----\n",
      "          Pred -  Pred +\n",
      "Actual -     290       3\n",
      "Actual +      24     182\n",
      "-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9236    0.9898    0.9555       293\n",
      "           1     0.9838    0.8835    0.9309       206\n",
      "\n",
      "   micro avg     0.9459    0.9459    0.9459       499\n",
      "   macro avg     0.9537    0.9366    0.9432       499\n",
      "weighted avg     0.9484    0.9459    0.9454       499\n",
      "\n",
      "-----\n",
      "Accuracy of KNN classifier on train set: 0.945892\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "analyze_knn_binomial(X_titanic_KNN_1, y_titanic_KNN_1, 5, 'distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using uniform as the measure of impurity and 10 as the number of neighbors.\n",
      "The features being used: ['pclass', 'age', 'sibsp', 'parch', 'sex_encode']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "[0 1 0 0 0]\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0.9 0.1]\n",
      " [0.2 0.8]\n",
      " [0.9 0.1]\n",
      " [0.5 0.5]\n",
      " [0.7 0.3]]\n",
      "-----\n",
      "Accuracy of KNN classifier on training set: 0.78356713\n",
      "-----\n",
      "          Pred -  Pred +\n",
      "Actual -     280      13\n",
      "Actual +      95     111\n",
      "-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7467    0.9556    0.8383       293\n",
      "           1     0.8952    0.5388    0.6727       206\n",
      "\n",
      "   micro avg     0.7836    0.7836    0.7836       499\n",
      "   macro avg     0.8209    0.7472    0.7555       499\n",
      "weighted avg     0.8080    0.7836    0.7700       499\n",
      "\n",
      "-----\n",
      "Accuracy of KNN classifier on train set: 0.783567\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "analyze_knn_binomial(X_titanic_KNN_1, y_titanic_KNN_1, 10, 'uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using uniform as the measure of impurity and 20 as the number of neighbors.\n",
      "The features being used: ['pclass', 'age', 'sibsp', 'parch', 'sex_encode']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "[0 1 0 0 0]\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0.85 0.15]\n",
      " [0.2  0.8 ]\n",
      " [0.8  0.2 ]\n",
      " [0.55 0.45]\n",
      " [0.75 0.25]]\n",
      "-----\n",
      "Accuracy of KNN classifier on training set: 0.72745491\n",
      "-----\n",
      "          Pred -  Pred +\n",
      "Actual -     271      22\n",
      "Actual +     114      92\n",
      "-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7039    0.9249    0.7994       293\n",
      "           1     0.8070    0.4466    0.5750       206\n",
      "\n",
      "   micro avg     0.7275    0.7275    0.7275       499\n",
      "   macro avg     0.7555    0.6858    0.6872       499\n",
      "weighted avg     0.7465    0.7275    0.7068       499\n",
      "\n",
      "-----\n",
      "Accuracy of KNN classifier on train set: 0.727455\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "analyze_knn_binomial(X_titanic_KNN_1, y_titanic_KNN_1, 20, 'uniform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most accurate model was using distance and 5 max levels deep.  While using uniform as the weight, there was a significant lack in accuracy as max level increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_rf_binomial(X_df, y_df, string_criterion, min_sample_leaf_input, max_depth_input):\n",
    "    features = list(X_df)\n",
    "    \n",
    "    print('Results using ' + str(string_criterion) + ' as the measure of impurity and ' + str(max_depth_input) + ' as max depth level and ' +str(min_sample_leaf_input) + ' as the min_sample_leaf.')\n",
    "    print('The features being used: ' + str(features))\n",
    "    print('-----')\n",
    "    X_df_train, X_df_test, y_df_train, y_df_test = train_test_split(X_df, y_df, test_size = .30, random_state=123)\n",
    "    X_df_train.head()\n",
    "\n",
    "    rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion=string_criterion,\n",
    "                            min_samples_leaf=min_sample_leaf_input,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=max_depth_input, \n",
    "                            random_state=123)\n",
    "\n",
    "    rf.fit(X_df_train, y_df_train)\n",
    "\n",
    "    y_df_pred = rf.predict(X_df_train)\n",
    "    print('Head of predicted on X_train:')\n",
    "    print(y_df_pred[0:5])\n",
    "    print('-----')\n",
    "\n",
    "    y_df_pred_proba = rf.predict_proba(X_df_train)\n",
    "    print('Head of probabilities on X_train:')\n",
    "    print(y_df_pred_proba[0:5])\n",
    "    print('-----')\n",
    "\n",
    "    print('Accuracy of rf classifier on training set: {:.8f}'.format(rf.score(X_df_train, y_df_train)))\n",
    "    print('-----')\n",
    "    \n",
    "    cm = pd.DataFrame(confusion_matrix(y_df_train, y_df_pred),\n",
    "             columns=['Pred -', 'Pred +'], index=['Actual -', 'Actual +'])\n",
    "    \n",
    "    print(cm)\n",
    "    print('-----')\n",
    "    \n",
    "    print(classification_report(y_df_train, y_df_pred, digits=4))\n",
    "    print('-----')\n",
    "    \n",
    "    y_df_pred_test = rf.predict(X_df_test)\n",
    "    y_df_pred_proba_test = rf.predict_proba(X_df_test)\n",
    "    print('Accuracy of RF classifier on train set: {:.6f}'\n",
    "     .format(rf.score(X_df_train, y_df_train)))\n",
    "    print('-----')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using gini as the measure of impurity and 20 as max depth level and 1 as the min_sample_leaf.\n",
      "The features being used: ['pclass', 'age', 'sibsp', 'parch', 'sex_encode']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "[0 1 0 1 1]\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0.87633067 0.12366933]\n",
      " [0.03       0.97      ]\n",
      " [1.         0.        ]\n",
      " [0.         1.        ]\n",
      " [0.02       0.98      ]]\n",
      "-----\n",
      "Accuracy of rf classifier on training set: 0.94589178\n",
      "-----\n",
      "          Pred -  Pred +\n",
      "Actual -     284       9\n",
      "Actual +      18     188\n",
      "-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9404    0.9693    0.9546       293\n",
      "           1     0.9543    0.9126    0.9330       206\n",
      "\n",
      "   micro avg     0.9459    0.9459    0.9459       499\n",
      "   macro avg     0.9474    0.9410    0.9438       499\n",
      "weighted avg     0.9461    0.9459    0.9457       499\n",
      "\n",
      "-----\n",
      "Accuracy of RF classifier on train set: 0.945892\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "analyze_rf_binomial(X_titanic_KNN_1, y_titanic_KNN_1, 'gini', 1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using entropy as the measure of impurity and 20 as max depth level and 1 as the min_sample_leaf.\n",
      "The features being used: ['pclass', 'age', 'sibsp', 'parch', 'sex_encode']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "[0 1 0 1 1]\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0.87633067 0.12366933]\n",
      " [0.06666667 0.93333333]\n",
      " [1.         0.        ]\n",
      " [0.         1.        ]\n",
      " [0.02       0.98      ]]\n",
      "-----\n",
      "Accuracy of rf classifier on training set: 0.94589178\n",
      "-----\n",
      "          Pred -  Pred +\n",
      "Actual -     284       9\n",
      "Actual +      18     188\n",
      "-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9404    0.9693    0.9546       293\n",
      "           1     0.9543    0.9126    0.9330       206\n",
      "\n",
      "   micro avg     0.9459    0.9459    0.9459       499\n",
      "   macro avg     0.9474    0.9410    0.9438       499\n",
      "weighted avg     0.9461    0.9459    0.9457       499\n",
      "\n",
      "-----\n",
      "Accuracy of RF classifier on train set: 0.945892\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "analyze_rf_binomial(X_titanic_KNN_1, y_titanic_KNN_1, 'entropy', 1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using gini as the measure of impurity and 3 as max depth level and 5 as the min_sample_leaf.\n",
      "The features being used: ['pclass', 'age', 'sibsp', 'parch', 'sex_encode']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "[0 1 0 1 1]\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0.85118297 0.14881703]\n",
      " [0.49624102 0.50375898]\n",
      " [0.83718195 0.16281805]\n",
      " [0.14479103 0.85520897]\n",
      " [0.22619012 0.77380988]]\n",
      "-----\n",
      "Accuracy of rf classifier on training set: 0.83567134\n",
      "-----\n",
      "          Pred -  Pred +\n",
      "Actual -     282      11\n",
      "Actual +      71     135\n",
      "-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7989    0.9625    0.8731       293\n",
      "           1     0.9247    0.6553    0.7670       206\n",
      "\n",
      "   micro avg     0.8357    0.8357    0.8357       499\n",
      "   macro avg     0.8618    0.8089    0.8201       499\n",
      "weighted avg     0.8508    0.8357    0.8293       499\n",
      "\n",
      "-----\n",
      "Accuracy of RF classifier on train set: 0.835671\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "analyze_rf_binomial(X_titanic_KNN_1, y_titanic_KNN_1, 'gini', 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using entropy as the measure of impurity and 3 as max depth level and 5 as the min_sample_leaf.\n",
      "The features being used: ['pclass', 'age', 'sibsp', 'parch', 'sex_encode']\n",
      "-----\n",
      "Head of predicted on X_train:\n",
      "[0 1 0 1 1]\n",
      "-----\n",
      "Head of probabilities on X_train:\n",
      "[[0.85085113 0.14914887]\n",
      " [0.49409506 0.50590494]\n",
      " [0.83759766 0.16240234]\n",
      " [0.13541377 0.86458623]\n",
      " [0.20952814 0.79047186]]\n",
      "-----\n",
      "Accuracy of rf classifier on training set: 0.83567134\n",
      "-----\n",
      "          Pred -  Pred +\n",
      "Actual -     273      20\n",
      "Actual +      62     144\n",
      "-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8149    0.9317    0.8694       293\n",
      "           1     0.8780    0.6990    0.7784       206\n",
      "\n",
      "   micro avg     0.8357    0.8357    0.8357       499\n",
      "   macro avg     0.8465    0.8154    0.8239       499\n",
      "weighted avg     0.8410    0.8357    0.8318       499\n",
      "\n",
      "-----\n",
      "Accuracy of RF classifier on train set: 0.835671\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "analyze_rf_binomial(X_titanic_KNN_1, y_titanic_KNN_1, 'entropy', 5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For training the model, increasing max depth level and going down to leaves that have one instance is much more accurate.  There is a possibility that running this on the test sample would lead to poor results as the model could be overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=123, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_titanic_rf_train, X_titanic_rf_test, y_titanic_rf_train, y_titanic_rf_test = train_test_split(X_titanic_KNN_1, y_titanic_KNN_1, test_size = .30, random_state=123)\n",
    "X_titanic_rf_train.head()\n",
    "\n",
    "forest_fit = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=1,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=20, \n",
    "                            random_state=123)\n",
    "\n",
    "forest_fit.fit(X_titanic_rf_train, y_titanic_rf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
