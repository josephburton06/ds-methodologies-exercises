{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "     .master(\"local\")\\\n",
    "     .appName(\"mylocalconnection\")\\\n",
    "     .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = spark.createDataFrame([('English', ), ('Spanish', ), ('French', )], schema=['language', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "langs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|language|\n",
      "+--------+\n",
      "| English|\n",
      "| Spanish|\n",
      "|  French|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "langs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_dataframe = pd.DataFrame(dict(n=np.arange(100), group=np.random.choice(list('abc'), 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|  n|group|\n",
      "+---+-----+\n",
      "|  0|    b|\n",
      "|  1|    c|\n",
      "|  2|    a|\n",
      "|  3|    a|\n",
      "|  4|    b|\n",
      "|  5|    b|\n",
      "|  6|    c|\n",
      "|  7|    b|\n",
      "|  8|    c|\n",
      "|  9|    c|\n",
      "| 10|    b|\n",
      "| 11|    c|\n",
      "| 12|    c|\n",
      "| 13|    b|\n",
      "| 14|    a|\n",
      "| 15|    a|\n",
      "| 16|    a|\n",
      "| 17|    c|\n",
      "| 18|    b|\n",
      "| 19|    b|\n",
      "+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|group|            avg(n)|\n",
      "+-----+------------------+\n",
      "|    c| 48.75675675675676|\n",
      "|    b| 43.34615384615385|\n",
      "|    a|54.567567567567565|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('group').agg(expr('avg(n)')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|group|            avg(n)|\n",
      "+-----+------------------+\n",
      "|    c| 48.75675675675676|\n",
      "|    b| 43.34615384615385|\n",
      "|    a|54.567567567567565|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby(df.group).agg(avg(df.n)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a local SQL table from the DF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('numbers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|group|              mean|\n",
      "+-----+------------------+\n",
      "|    c| 48.75675675675676|\n",
      "|    b| 43.34615384615385|\n",
      "|    a|54.567567567567565|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "another_pandas_dataframe = spark.sql('''\n",
    "SELECT group, avg(n) as mean\n",
    "FROM numbers\n",
    "GROUP BY group\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|group|count|\n",
      "+-----+-----+\n",
      "|    c|   37|\n",
      "|    b|   26|\n",
      "|    a|   37|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('group').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|group|sum(n)|\n",
      "+-----+------+\n",
      "|    c|  1804|\n",
      "|    b|  1127|\n",
      "|    a|  2019|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('group').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+\n",
      "|group| sum|\n",
      "+-----+----+\n",
      "|    c|1804|\n",
      "|    b|1127|\n",
      "|    a|2019|\n",
      "+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "SELECT group, sum(n) as sum\n",
    "FROM numbers\n",
    "GROUP BY group\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
